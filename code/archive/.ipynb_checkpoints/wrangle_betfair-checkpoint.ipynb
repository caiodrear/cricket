{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0d3b19d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d2d90295005428794303bea27d8368d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processing bz2s:   0%|          | 0/10598 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5228/586349139.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[0mbetfair_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../../data/betfair_data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[1;31m#---------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m \u001b[0mbetfair_wrangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5228/586349139.py\u001b[0m in \u001b[0;36mbetfair_wrangle\u001b[1;34m(file_name_list, results)\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[0mgen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m             match_list += [market_row(market_books[0]) for market_books in gen() if\n\u001b[0m\u001b[0;32m     82\u001b[0m                            len(market_books[0].runners) == 2]\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5228/586349139.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[0mgen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m             match_list += [market_row(market_books[0]) for market_books in gen() if\n\u001b[0m\u001b[0;32m     82\u001b[0m                            len(market_books[0].runners) == 2]\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\caio\\documents\\python\\gayle\\gayle_env\\lib\\site-packages\\betfairlightweight\\streaming\\betfairstream.py\u001b[0m in \u001b[0;36m_read_loop\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moperation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mupdate\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m                     \u001b[1;31m# if on_data returns an error stop the stream and raise error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\bz2.py\u001b[0m in \u001b[0;36mreadline\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_can_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\_compression.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mview\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"B\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbyte_view\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m             \u001b[0mbyte_view\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\_compression.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    101\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m                     \u001b[0mrawblock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mb\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrawblock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#------------------standard packages-----------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from tqdm.notebook import tqdm\n",
    "from thefuzz import fuzz, process\n",
    "\n",
    "#-----------------load_bz2 packages------------------\n",
    "import os\n",
    "from typing import List\n",
    "from unittest.mock import patch\n",
    "import tarfile\n",
    "import zipfile\n",
    "import bz2\n",
    "import glob\n",
    "\n",
    "#-----------------streaming packages-----------------\n",
    "import logging\n",
    "import betfairlightweight\n",
    "from betfairlightweight import StreamListener\n",
    "\n",
    "#-----------------caio's modules---------------------\n",
    "from cricsheet_read import cricsheet_read #data processing\n",
    "\n",
    "#----------------------load bz2----------------------\n",
    "def load_bz2(file_paths: List[str]): #the path directories to the data sets\n",
    "    for file_path in file_paths:     #accepts tar files, zipped files or directory with bz2 file(s)\n",
    "        if os.path.isdir(file_path):\n",
    "            for path in glob.iglob(file_path + '**/**/*.bz2', recursive=True):\n",
    "                f = bz2.BZ2File(path, 'rb')\n",
    "                yield f\n",
    "                f.close()\n",
    "        elif os.path.isfile(file_path):\n",
    "            ext = os.path.splitext(file_path)[1]\n",
    "            # iterate through a tar archive\n",
    "            if ext == '.tar':\n",
    "                with tarfile.TarFile(file_path) as archive:\n",
    "                    for file in archive:\n",
    "                        yield bz2.open(archive.extractfile(file))\n",
    "            # or a zip archive\n",
    "            elif ext == '.zip':\n",
    "                with zipfile.ZipFile(file_path) as archive:\n",
    "                    for file in archive.namelist():\n",
    "                        yield bz2.open(archive.open(file))\n",
    "\n",
    "#----------------betfair wrangle--------------------\n",
    "def betfair_wrangle(file_name_list = ['data_post_apr20', 'data_pre_apr20'], results = cricsheet_read()[1]):\n",
    "#-----------------betfair login---------------------\n",
    "    logging.basicConfig(level = logging.ERROR)\n",
    "    trading = betfairlightweight.APIClient('username', 'password', 'app_key')\n",
    "    listener = StreamListener(max_latency=None)\n",
    "\n",
    "#----------------get attributes---------------------\n",
    "    def market_row(market_book):\n",
    "\n",
    "        row_dict = {}\n",
    "\n",
    "        row_dict['market_id'] = market_book.market_id\n",
    "        row_dict['start_date'] = market_book.publish_time\n",
    "        #row_dict['status'] = market_book.status\n",
    "        row_dict['inplay'] = market_book.inplay                                     #blast name fix for warwickshire\n",
    "        row_dict['team_h'] = market_book.market_definition.runners[0].name.replace('Birmingham Bears', 'Warwickshire')\n",
    "        row_dict['team_a'] = market_book.market_definition.runners[1].name.replace('Birmingham Bears', 'Warwickshire')\n",
    "        row_dict['team_h_sp'] = market_book.runners[0].last_price_traded or np.NaN\n",
    "        row_dict['team_a_sp'] = market_book.runners[1].last_price_traded or np.NaN\n",
    "\n",
    "        return row_dict\n",
    "\n",
    "#-----------------process files---------------------\n",
    "    file_path_list = ['../../data/' + file_name + '.tar' for file_name in file_name_list]\n",
    "    no_files = len([file for file in load_bz2(file_path_list)])\n",
    "\n",
    "    match_list = []\n",
    "    for file in tqdm(load_bz2(file_path_list), total = no_files, desc = 'processing bz2s'):\n",
    "\n",
    "        stream = trading.streaming.create_historical_generator_stream(file_path = file, listener = listener)\n",
    "\n",
    "        with patch(\"builtins.open\", lambda f, _: f):\n",
    "            gen = stream.get_generator()\n",
    "\n",
    "            match_list += [market_row(market_books[0]) for market_books in gen() if\n",
    "                           len(market_books[0].runners) == 2]\n",
    "\n",
    "#---------------get starting prices-----------------\n",
    "    betfair_data = pd.DataFrame.from_dict(match_list).sort_values(['market_id', 'start_date'])\n",
    "    betfair_data['start_date'] = betfair_data['start_date'].dt.date\n",
    "    betfair_data.insert(2, 'match_name', betfair_data['team_h'] + ' v ' + betfair_data['team_a'])\n",
    "    \n",
    "    betfair_data = betfair_data[(betfair_data['inplay'].shift(1) != betfair_data['inplay']) &\n",
    "                                (betfair_data['inplay'] == True)].drop('inplay',\n",
    "                                 axis = 1).drop_duplicates('market_id').set_index('market_id',\n",
    "                                                                                  drop = True).dropna()  \n",
    "    betfair_data.to_csv('../../data/betfair_data.csv')\n",
    "    \n",
    "#----------------map to master data-----------------\n",
    "    post_may_15 = results[results['start_date'] >= dt.date(2015, 5, 1)].copy()\n",
    "    post_may_15['match_name'] = post_may_15['match_name'].str.replace('Birmingham Bears', 'Warwickshire')\n",
    "\n",
    "    team_dict = {row:{betfair_data.loc[row]['team_h']:betfair_data.loc[row]['team_h_sp'],\n",
    "                      betfair_data.loc[row]['team_a']:betfair_data.loc[row]['team_a_sp']} for row in betfair_data.index}\n",
    "\n",
    "    def fuzz_row(match_id):\n",
    "        row_dict = {}\n",
    "\n",
    "        nearby_matches = betfair_data[abs(betfair_data['start_date'] - post_may_15['start_date'].loc[match_id]).dt.days < 1]\n",
    "\n",
    "        match_found = process.extractOne(post_may_15['match_name'].loc[match_id], nearby_matches['match_name'],\n",
    "                                         score_cutoff = 90, scorer = fuzz.token_set_ratio)\n",
    "        if match_found is not None:\n",
    "\n",
    "            row_dict['match_id'] = match_id\n",
    "            runners = team_dict[match_found[2]]\n",
    "            for team in ['set_', 'chase_']:\n",
    "                row_dict[team + 'odds'] = runners[process.extractOne(results[team + 'team'].loc[row], runners.keys(),\n",
    "                                                                     score_cutoff = 0, scorer = fuzz.token_set_ratio)[0]]\n",
    "        else:\n",
    "            for col in ['match_id', 'set_odds', 'chase_odds']:\n",
    "                row_dict[col] = np.NaN\n",
    "                \n",
    "        return row_dict\n",
    "\n",
    "    betfair_data = pd.DataFrame.from_dict([fuzz_row(row) for row in\n",
    "                                           tqdm(post_may_15.index, desc = 'mapping marktet_ids to match_id')])\n",
    "\n",
    "    print('master_data odds percentage:', str(np.round((betfair_data.notna().sum()[0]/len(betfair_data))*100,2)) + '%')\n",
    "    betfair_data = betfair_data.dropna().set_index('match_id')\n",
    "    \n",
    "#---------------------save csv----------------------\n",
    "    betfair_data.to_csv('../../data/betfair_data.csv')\n",
    "#---------------------------------------------------\n",
    "betfair_wrangle()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
